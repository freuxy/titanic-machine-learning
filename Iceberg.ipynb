{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxRlkR6hwz12"
      },
      "source": [
        "# Iceberg Image Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmPBb92Iwz15"
      },
      "source": [
        "To avoid another disaster similar to Titanic, we want to create a model that is able to predict from satellite images if an object is an iceberg or a ship.\n",
        "\n",
        "We use a dataset of satellite images, our goal is to understand it and create a model using this dataset to be able to predict from a given satellite image if it corresponds to a ship or an iceberg. Using these predictions we would know the areas to avoid when traveling by sea.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vo-2aOn3wz15"
      },
      "source": [
        "## 1) Data acquisition\n",
        "We load the data from its location and explore it :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "U_pvbDVPwz16",
        "outputId": "cdc8a4e3-bef5-44d8-d90c-708aedf1f6be",
        "tags": []
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Unexpected character found when decoding array value (2)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-f4fb5b4c5476>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Importing the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_lines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_get_object_parser\u001b[0;34m(self, json)\u001b[0m\n\u001b[1;32m    935\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"frame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFrameParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"series\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1062\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1064\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_no_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_parse_no_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1319\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m             self.obj = DataFrame(\n\u001b[0;32m-> 1321\u001b[0;31m                 \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecise_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecise_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m             )\n\u001b[1;32m   1323\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"split\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unexpected character found when decoding array value (2)"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "# Importing the data\n",
        "df_train = pd.read_json('data/iceberg/train.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "7BNKR8-Qwz17",
        "outputId": "2347132a-3534-41ea-addc-30ba8e2ae302",
        "tags": []
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'df_train' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-bef27c3f3a9b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Checking some train data examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df_train' is not defined"
          ]
        }
      ],
      "source": [
        "# Checking some train data examples\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMgjY0Kawz17",
        "tags": []
      },
      "outputs": [],
      "source": [
        "df_train.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODUif5-ewz17"
      },
      "source": [
        "## 2) Data preparation\n",
        "We load the data from its location and explore it :\n",
        "### 2.1) Variables Signification\n",
        "<ul>\n",
        "<li>id - the id of the image</li>\n",
        "<li>band_1, band_2 - the flattened image data. Each band has 75x75 pixel values in the list, so the list has 5625 elements. Note that these values are not the normal non-negative integers in image files since they have physical meanings - these are float numbers with unit being dB. Band 1 and Band 2 are signals characterized by radar backscatter produced from different polarizations at a particular incidence angle. The polarizations correspond to HH (transmit/receive horizontally) and HV (transmit horizontally and receive vertically). More background on the satellite imagery can be found here.</li>\n",
        "<li>inc_angle - the incidence angle of which the image was taken. Note that this field has missing data marked as \"na\", and those images with \"na\" incidence angles are all in the training data to prevent leakage.</li>\n",
        "<li>is_iceberg - the target variable, set to 1 if it is an iceberg, and 0 if it is a ship. This field only exists in train.json.</li>\n",
        "</ul>\n",
        "\n",
        "### 2.2) Missing data\n",
        "Let us check for the presence of <b>na</b> values in the <i>inc_angle</i> variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVmlesb-wz17",
        "tags": []
      },
      "outputs": [],
      "source": [
        "len(df_train[df_train['inc_angle']=='na'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-U4_P8wUwz18",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# We replace the 'na' string values with nan values so it can be easily handled\n",
        "df_train['inc_angle'].replace('na',np.nan, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AILBV2rUwz19",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Now the df info shows that there are null values in inc_angle which was not visible before\n",
        "df_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9UwQBnJwz19",
        "tags": []
      },
      "outputs": [],
      "source": [
        "df_train['inc_angle'] = df_train['inc_angle'].replace('na',np.nan)\n",
        "\n",
        "# Let's drop the NaN values.\n",
        "trainData_noNaN = df_train.dropna()\n",
        "\n",
        "# From the noNaN dataset, let's get the mean and standard deviation.\n",
        "incAngleTrain_noNaN = np.array(trainData_noNaN['inc_angle'], dtype=float)\n",
        "incAngleMean = incAngleTrain_noNaN.mean(dtype=np.float64)\n",
        "incAngleStd = incAngleTrain_noNaN.std(dtype=np.float64)\n",
        "\n",
        "# Using the mean and standard deviation, normalize the inclination angle to zero mean and standard deviation of 1.\n",
        "df_train['inc_angle'] -= incAngleMean\n",
        "df_train['inc_angle'] /= incAngleStd\n",
        "\n",
        "# Replace the NaN values with the mean value, 0.0\n",
        "df_train['inc_angle'] = df_train['inc_angle'].replace(np.nan, 0.0)\n",
        "\n",
        "incAngleTrain = df_train['inc_angle']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Hlnz0b2wz1-"
      },
      "source": [
        "### 2.3) Exploratory Data analysis\n",
        "Do we really need two variables (band 1 & 2)?\n",
        "Let us check their distribution :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pV6bjlx9wz1-",
        "tags": []
      },
      "outputs": [],
      "source": [
        "totalBand1 = []\n",
        "totalBand2 = []\n",
        "for imageVector in df_train['band_1']:\n",
        "    for dB in imageVector:\n",
        "        totalBand1.append(dB)\n",
        "for imageVector in df_train['band_2']:\n",
        "    for dB in imageVector:\n",
        "        totalBand2.append(dB)\n",
        "sns.distplot(totalBand1, label='Band 1')\n",
        "sns.distplot(totalBand2, label='Band 2')\n",
        "plt.legend()\n",
        "plt.autoscale()\n",
        "plt.xlabel('Radar Backscatter (dB)')\n",
        "plt.ylabel('Density')\n",
        "plt.savefig('Radar Backscatter Distribution.jpg')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JBWMo60hbOt"
      },
      "source": [
        "## Commentaire:\n",
        "### _Ce graphique illustre la relation entre la rétrodiffusion des radars et la densité des bandes 1 et 2. La densité de la bande 2 est initialement d'environ 0.135 pour une rétrodiffusion d'environ -30 dB, mais diminue rapidement à partir de -20 dB pour atteindre 0 à -10 dB. En revanche, la densité de la bande 1 augmente jusqu'à environ 0.08, puis diminue progressivement à partir de -10 dB pour atteindre 0 à 0 dB._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuPBVj3Wwz1_"
      },
      "source": [
        "### 2.4) Image visualisation :\n",
        "Since the band 1 & 2 are images, let us plot them alongside their labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XdkAIzVwz1_"
      },
      "source": [
        "Given the distribution visualised, should we keep both variables? Why?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZ7nJG7Pwz1_",
        "tags": []
      },
      "outputs": [],
      "source": [
        "f, axarr = plt.subplots(nrows=2, ncols=6, sharex=True, sharey=True, figsize=(6,2), dpi=300)\n",
        "for img in range (6):\n",
        "    axarr[0, img].imshow(np.array(df_train['band_1'][img]).reshape((75,75)),cmap='binary_r')\n",
        "    if df_train['is_iceberg'][img]==0:\n",
        "        axarr[0, img].set_title('Ship')\n",
        "    else:\n",
        "        axarr[0, img].set_title('Iceberg')\n",
        "    axarr[1, img].imshow(np.array(df_train['band_2'][img]).reshape((75,75)),cmap='binary_r')\n",
        "axarr[0, 0].set_ylabel('Band 1')\n",
        "axarr[1, 0].set_ylabel('Band 2')\n",
        "plt.savefig('radar.jpg')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ISoFjg4wz1_"
      },
      "source": [
        "### 2.5) Data splitting and preparation :\n",
        "We need to split our data into two sets : training and validation\n",
        "\n",
        "We also need to reshape and normalize the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--kaiJfEwz1_",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# TO-DO :\n",
        "#   - Separate the target from the features\n",
        "#   - Split the data into train and validation\n",
        "Y_train = df_train.iloc[:,-1]\n",
        "X_train = df_train.iloc[:,1:4]\n",
        "X_train, X_valid, Y_train, Y_valid = train_test_split(X_train, Y_train, random_state=1, train_size=0.8)\n",
        "print(X_train.shape, Y_train.shape)\n",
        "print(X_valid.shape, Y_valid.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IE-Amwl3wz2A",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Function used to reshape and normalize\n",
        "def reshape_normalize(band):\n",
        "    radarImage = np.empty([1,75,75,1])\n",
        "    for vector in band:\n",
        "        bandMatrix = np.array(vector).reshape((75, 75))\n",
        "        bandMatrix = (bandMatrix - bandMatrix.min()) / (bandMatrix.max() - bandMatrix.min())\n",
        "        bandMatrix = np.expand_dims(bandMatrix, axis=0)\n",
        "        bandMatrix = np.expand_dims(bandMatrix, axis=-1)\n",
        "        radarImage = np.concatenate((radarImage, bandMatrix))\n",
        "    radarImage = np.delete(radarImage, 0, 0)\n",
        "    return radarImage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWXI4oX9wz2A",
        "tags": []
      },
      "outputs": [],
      "source": [
        "band_1_train = reshape_normalize(X_train['band_1'])\n",
        "band_2_train = reshape_normalize(X_train['band_2'])\n",
        "angle_train = X_train['inc_angle']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-7zVWB7wz2A"
      },
      "source": [
        "## 3) Model creation :\n",
        "Now that our data is ready, we need to create our model.\n",
        "\n",
        "Unlike the sequential models that we have seen before, this time we will create a non-sequential model. This model has three separate branches that are later merged :\n",
        "\n",
        "<ol>\n",
        "<li>Convolutional Model for the first band</li>\n",
        "<li>Convolutional Model for the second band</li>\n",
        "<li>Input layer for the inc_angle</li>\n",
        "</ol>\n",
        "\n",
        "These three 'models' are then merged and fed to a Fully Connected Neural Network (Dense)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYkVgKu9wz2A",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout\n",
        "from keras.models import Model, Sequential\n",
        "from keras import optimizers\n",
        "from keras import regularizers\n",
        "\n",
        "band1 = Input(shape=(75,75,1))\n",
        "band2 = Input(shape=(75,75,1))\n",
        "angle = Input(shape=(1))\n",
        "\n",
        "# TO-DO :\n",
        "#   - Complete the two convolution models\n",
        "#   - Combine the results of the convolution models with inc_angle variable and feed them to an mlp\n",
        "\n",
        "# Define the model architecture\n",
        "# Start with Convolutional Model 1 for Band 1 Data\n",
        "conv1 = Conv2D(filters= 64, kernel_size=5, strides=1, padding='same', activation='elu', input_shape=(75, 75, 1))(band1)\n",
        "conv1 = MaxPooling2D(pool_size=2,strides=2)(conv1)\n",
        "conv1 = Conv2D(filters= 128, kernel_size=4, strides=1, padding='same', activation='elu')(conv1)\n",
        "conv1 = MaxPooling2D(pool_size=2,strides=2)(conv1)\n",
        "\n",
        "conv1 = GlobalAveragePooling2D()(conv1)\n",
        "\n",
        "# Start with Convolutional Model 2 for Band 2 Data\n",
        "conv2 = Conv2D(filters= 64, kernel_size=5, strides=1, padding='same', activation='elu', input_shape=(75, 75, 1))(band2)\n",
        "conv2 = MaxPooling2D(pool_size=2,strides=2)(conv2)\n",
        "conv2 = Conv2D(filters= 128, kernel_size=4, strides=1, padding='same', activation='elu')(conv2)\n",
        "conv2 = MaxPooling2D(pool_size=2,strides=2)(conv2)\n",
        "\n",
        "conv2 = GlobalAveragePooling2D()(conv2)\n",
        "\n",
        "# Combine the convolution models' outputs as well as the inc_angle\n",
        "merge = keras.layers.concatenate([conv1, conv2, angle])\n",
        "\n",
        "# Let's use a final multi-layer perceptron to weigh the three inputs\n",
        "mlp = Dense(500, activation='elu')(merge)\n",
        "mlp = Dense(256, activation='elu')(mlp)\n",
        "mlp = Dense(128, activation='elu')(mlp)\n",
        "\n",
        "output = Dense(1, activation='sigmoid')(mlp)\n",
        "\n",
        "model = Model(inputs = [band1, band2, angle], outputs = output)\n",
        "\n",
        "#Compile the model\n",
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2pYhAtgwz2B",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# TO-DO : Train the model\n",
        "model.fit(x=[band_1_train, band_2_train, angle_train ], y =Y_train , epochs = 50, verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXrMJUMtwz2B",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Prepare the data for the validation set\n",
        "band_1_test = reshape_normalize(X_valid['band_1'])\n",
        "band_2_test = reshape_normalize(X_valid['band_2'])\n",
        "angle_test = X_valid['inc_angle']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sP0I6emFwz2B",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Evaluate your model\n",
        "# TO-DO : Specify the parameters for this function\n",
        "score = model.evaluate([band_1_test, band_2_test, angle_test], Y_valid)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
